{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Multiple Linear Regression Using Gradient Descent And Stochastic Gradient Descent Algorithm.\n",
    "\n",
    "In this assignment, you will be implementing Multiple Linear Regression Model on the same data set as in programming_assignment_1b, but here we will be using gradient descent algorithm (GDA) and stochastic gradient descent algorithm (SGDA) to minimize the cost function as taught in the class. The SGDA implementation is optional.\n",
    "\n",
    "Please add your own print statements to check your code to ensure your code is correct in every step.  (Note: we will not be grading the print statements you add to your code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this code cell using shift+enter before moving further\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data set.\n",
    "\n",
    "In the below code cell, you will load the data using python pandas library as done in the programming_assignment_1b. Use pd.read_csv('File url ', header=None,.... ) with the value of header=None,delim_whitespace=True,names=names,na_values='?' as attributes. The url for the .data file is https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data. This step is same as done in programming_assignment_1b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After completing the code in this code cell, run this code cell before moving further.\n",
    "names =[\n",
    "    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', \n",
    "    'AGE',  'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'PRICE'\n",
    "]\n",
    "\n",
    "#Write your code below to save dataframe in the df variable below. \n",
    "# In place of None, write the pandas command to read the csv file.\n",
    "df= pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data', header = None, delim_whitespace = True, names = names, na_values = '?')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of taking just 1 feature i.e 'RM' as we did in Simple Linear Regression, we will use 4 features which are 'LSTAT', 'DIS', 'RM' and 'INDUS'. We choose only these features because they are almost on similar scale. So, there is no need for feature scaling. Fetching the values of 5 columns into a smaller dataframe (say) df1 from df. This step is also same as done in programming_assignment_1b.There we fetched only 2 columns but here we need 5 columns.We need the values in the 'PRICE', 'LSTAT', 'DIS', 'RM' and 'INDUS' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 5)\n"
     ]
    }
   ],
   "source": [
    "#  After completing the code in this code cell, run this code cell before moving further. Also, save the values in df2 after dropping empty rows from df1\n",
    "# Write your code below.\n",
    "df1=df[['LSTAT', 'DIS', 'RM', 'INDUS', 'PRICE']]\n",
    "df2=df1.dropna()\n",
    "print(df2.shape)\n",
    "# Check the shape of df2. It should be (506,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vector y having the values of 'PRICE' column and matrix x having the values of  'LSTAT', 'DIS', 'RM' and 'INDUS' columns. We have already written the code for that. Just run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 4)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# Just run this code cell\n",
    "df3 = df2[['LSTAT', 'DIS', 'RM', 'INDUS']]\n",
    "x=df3.values\n",
    "y=np.array(df2['PRICE'])\n",
    "# Check the shape of x and y vectors.\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape y to be rank 2. After checking the shape of x and y in the above code cell, we see that x is already rank 2 and y are rank 1 matrix. Before moving ahead, convert y to be rank 2 matrix. For example, I would use the command y=y.reshape(y.shape[0],1) to reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After completing the code in this code cell, run this code cell before moving further. \n",
    "# Write your code below\n",
    "y = y.reshape(y.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the value of n i.e. number of training examples. \n",
    "Hint: Value of n is equal to the number of rows in either x or y matrix which can be accessed using numpy shape command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After completing the code in this code cell, run this code cell before moving further. \n",
    "# Write your code below\n",
    "n = y.shape[0]\n",
    "# After writing a code, it is a good practice to verify that your code is correct. \n",
    "# For example, in this case you can print the value of n and check that it should be equal to 506.\n",
    "# Occasionally we created test code cell to verify your code. \n",
    "# However, you should do it for almost every code you write."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending a Column of ones in x: Just run the code cell below\n",
    "Warning: Just run the below code cell only once or you would be appending column of ones multiple times if you run the cell multiple times. If by mistake you run the code cell more than once, re-initilize the value of x again in the previous code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=np.ones((y.shape[0],1))\n",
    "x=np.hstack((a , x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 5)\n"
     ]
    }
   ],
   "source": [
    "# Shape of x should be (506,5)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function.\n",
    "Compute the cost: Write the code to compute the cost inside the function. Do not change the function name or function parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, beta, n):\n",
    "    #Write your code in place of None. Cost can be calculated using a single line of code.\n",
    "    # Remember beta is a vector here.\n",
    "    cost = np.sum((np.dot(x,beta) - y)**2) / (2*n)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving ahead, ensure that the code you have written to compute the cost is correct. Just run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296.073458498\n"
     ]
    }
   ],
   "source": [
    "beta_testcase=np.zeros((5,1))\n",
    "cost_verify= compute_cost(x, y, beta_testcase, n)\n",
    "\n",
    "print(cost_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should be equal to 296.073458498. If it's equal to this, then move ahead. Else, re-check your code and re-verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "Write the code to perform gradient descent in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x , y , learning_rate , beta , n , num_iters):\n",
    "    # In place of None, write the updated value of beta0 in temp0 and of beta1 in temp1\n",
    "    X = x.T\n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        # derivative vector is given by : X_train.Transpose *  (( X_train * betavector)- y)\n",
    "        AB_y = x.dot(beta) - y\n",
    "        #temp =  beta[i] - (learning_rate/n) * np.sum((beta[0] + x[i].dot(beta[i]) - y[i]) * x.T[i])\n",
    "        beta =  beta - (learning_rate/n) * X.dot(AB_y)\n",
    "        \n",
    "        \n",
    "        if(i%100==0):\n",
    "            # In place of None, call the cost you just coded above\n",
    "            cost= compute_cost(x,y,beta,n)\n",
    "            #print(\"Cost\")\n",
    "            #print(cost)\n",
    "             \n",
    "            \n",
    "            \n",
    "    return beta      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving ahead, ensure that your code to update beta is correct. Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.46236374]\n"
     ]
    }
   ],
   "source": [
    "beta_testcase=np.zeros((5,1))\n",
    "g=gradient_descent(x , y , 0.0049 , beta_testcase , n , 100000)\n",
    "print(g[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating the Batch Gradient Descent Function \n",
    "\n",
    "Integrating the above function into a single function multiple_linear_reg_model_gda: This function uses gradient descent algorithm to minimize the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiple_linear_reg_model_gda(x , y , n , learning_rate , num_iters):\n",
    "    #initialize the values of parameter vector beta. It should be a column vector of zeros of dimension(n,1)\n",
    "    beta = np.zeros((5,1))\n",
    "    \n",
    "    #calculate the initial cost by calling the function you coded above.\n",
    "    initial_cost= compute_cost(x,y,beta,n)\n",
    "    print(\"Initial Cost\")\n",
    "    print(initial_cost)\n",
    "    \n",
    "    #calculate the optimized value of gradients by calling the gradient_descent function coded above\n",
    "    \n",
    "    beta = gradient_descent(x , y , learning_rate , beta , n , num_iters)\n",
    "    \n",
    "    #Calculate the cost with the optimized value of beta0 and beta1 by calling the cost function.\n",
    "    \n",
    "    final_cost = compute_cost(x,y,beta,n)\n",
    "    print(\"Final Cost\")\n",
    "    print(final_cost)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when you have coded multiple_linear_reg_model_gda function, you can call this function to find the optimized values of parameters beta. Before calling the function, set the values of learning_rate and num_iters. You may have to call this function several number of times with different values of num_iters and learning_rate to find the optimal values of beta. For some values of learning_rate, it may give an error as the values of cost may reach a very high value(infinity) due to overshooting as discussed in the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost\n",
      "296.073458498\n",
      "Final Cost\n",
      "475817512.044\n"
     ]
    }
   ],
   "source": [
    "# Write your code below\n",
    "learning_rate = 0.005\n",
    "num_iters = 1000\n",
    "# In place of None, call the multiple_linear_reg_model_gda.\n",
    "beta = multiple_linear_reg_model_gda(x , y , n , learning_rate , num_iters)\n",
    "\n",
    "# The value of final cost should be 14.3470049896 or nearly this(depending on the values of learning_rate and num_itersations you choose.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Equation Method\n",
    "Now, we will be writing the code to find the values of parameters beta for our multiple linear regression model. This can also be used to cross-check the optimal values of beta we just found above using method above. These values should be same (or nearly same).\n",
    "Instead of writing the code for normal equation in one line, you can break this into 3 parts: First calculate q=inverse of (dot of (X.T,X)) (these are pseudo commands, use original numpy commands to calculate q). Then w= dot of ( X.T , y) and then beta_vec= dot of (q,w). Here, beta_vec is vector of dimension (5,1) having two values. Example beta0=beta_vec[0][0].\n",
    "\n",
    "Note : Do not append a column of ones in x because you have already done before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "q = np.linalg.inv(np.dot(x.T,x))\n",
    "w = np.dot(x.T,y)\n",
    "beta_vec = np.dot(q,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.29647186]\n",
      " [-0.66467285]\n",
      " [-0.90387731]\n",
      " [ 4.58064345]\n",
      " [-0.24342177]]\n"
     ]
    }
   ],
   "source": [
    "print(beta_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Values of beta you just got above should be approximately same as the ones you got using multiple_linear_reg_model_gda.\n",
    "This assignment ends here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Stochastic Gradient Descent (Optional / Ungraded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(x , y , learning_rate , beta , n , num_iters):\n",
    "\n",
    "    for j in range(num_iters):\n",
    "    \n",
    "        for i in range(0,n):\n",
    "        # Write updated value of beta vector in place of None\n",
    "            temp = None \n",
    "        \n",
    "            beta = temp\n",
    "   \n",
    "\n",
    "        if(j%2000==0):\n",
    "            cost= None\n",
    "            print(\"Cost\")\n",
    "            print(cost)\n",
    "            \n",
    "            \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiple_linear_reg_model_sgda(x , y , n , learning_rate , num_iters):\n",
    "    #initialize the values of parameter vector beta. It should be a column vector of zeros of dimension(m,1)\n",
    "    beta= None\n",
    "    \n",
    "    #calculate the initial cost by calling the function you coded above.\n",
    "    initial_cost=None\n",
    "    print(\"Initial Cost\")\n",
    "    print(initial_cost)\n",
    "    \n",
    "    #calculate the optimized value of gradients by calling the stochastic_gradient_descent function coded above\n",
    "    \n",
    "    beta= None\n",
    "    \n",
    "    #Calculate the cost with the optimized value of beta by calling the cost function.\n",
    "    \n",
    "    final_cost=None\n",
    "    print(\"Final Cost\")\n",
    "    print(final_cost)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when you have coded multiple_linear_reg_model_sgda function, you can call this function to find the optimized values of parameters beta. Before calling the function, set the values of learning_rate and num_iters. You may have to call this function several number of times with different values of num_iters and learning_rate to find the optimal values of parameters beta. For some values of learning_rate, it may give an error as the values of parameters may reach a very high value(infinity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code below\n",
    "learning_rate=None\n",
    "num_iters=None\n",
    "# In place of None, call the function multiple_linear_reg_model_sgda.\n",
    "beta=None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
